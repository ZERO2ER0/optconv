{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "EPOCH = 10   #遍历数据集次数\n",
    "BATCH_SIZE = 64      #批处理尺寸(batch_size)\n",
    "LR = 0.001        #学习率\n",
    " \n",
    "# 定义数据预处理方式\n",
    "transform = transforms.ToTensor()\n",
    " \n",
    "# 定义训练数据集\n",
    "trainset = tv.datasets.MNIST(root='/Users/lichen/Downloads/DataSets/',\n",
    "                             train=True,\n",
    "                             download= False,\n",
    "                             transform=transform)\n",
    "\n",
    "# 定义训练批处理数据\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True,\n",
    "    )\n",
    " \n",
    "# 定义测试数据集\n",
    "testset = tv.datasets.MNIST(root='/Users/lichen/Downloads/DataSets/',\n",
    "                            train=False,\n",
    "                            download=False,\n",
    "                            transform=transform)\n",
    " \n",
    "# 定义测试批处理数据\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数loss function 和优化方式（采用SGD）\n",
    "# 定义是否使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = fft_conv2d().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数，通常用于多分类问题上\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class fft_conv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, tile_size = 40, kernel_size = 32, tiling_factor = 4):\n",
    "        super(fft_conv2d, self).__init__()\n",
    "        self.tile_size = tile_size\n",
    "        self.kernel_size = kernel_size\n",
    "        self.tiling_factor = tiling_factor\n",
    "\n",
    "        pad_one, pad_two = int(np.ceil((self.tile_size - self.kernel_size)/2)), int(np.floor((self.tile_size - self.kernel_size)//2))\n",
    "        # self.kernels_lists = [[0, 0, 0 ,0],[0, 0, 0 ,0],[0, 0, 0 ,0],[0, 0 ,0 ,0]]\n",
    "        # for i in range(4):\n",
    "        #     for j in range(4):\n",
    "        #         names['kernels_' + str(i) + str(j)] = nn.Parameter(torch.rand(self.kernel_size, self.kernel_size, 2))\n",
    "        kernels_lists = [[0, 0, 0 ,0],[0, 0, 0 ,0],[0, 0, 0 ,0],[0, 0 ,0 ,0]]\n",
    "        \n",
    "        for i in range(self.tiling_factor):\n",
    "            for j in range(self.tiling_factor):\n",
    "                # self.names['kernels_' + str(i) + str(j)] = nn.Parameter(torch.rand(self.kernel_size, self.kernel_size, 2))\n",
    "                exec('self.kernel_{}{} = nn.Parameter(torch.rand(self.kernel_size, self.kernel_size, 2))'.format(i,j))\n",
    "                exec('kernels_lists[i][j] = self.kernel_{}{}'.format(i,j))\n",
    "        self.kernels_lists = kernels_lists\n",
    "        kernels_pad =[[F.pad(kernel, (0,0,pad_one,pad_two, pad_one,pad_two), 'constant', 0) for kernel in kernels]for kernels in                                    self.kernels_lists]\n",
    "        self.psf_pad = torch.cat([torch.cat(kernel_list, dim=0) for kernel_list in kernels_pad], dim=1)\n",
    "        self.fc1 = nn.Linear(32, 16)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fftconv2d(x, self.psf_pad, otf=None, adjoint=False, phase=True)\n",
    "        x = self.MaxPool2d_complex(x)\n",
    "        x = x.view(-1, 4 * 8)\n",
    "        x = self.fc1(x)\n",
    "        # nn.MaxPool2d(40, 40)\n",
    "        # x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        # x = self.classifier(x)\n",
    "        return x\n",
    "    def MaxPool2d_complex(self, a_tensor):\n",
    "        # shape = (1,1,160,160,2)\n",
    "        a_r, a_j = a_tensor.split(1,-1)\n",
    "        a_r = a_r.squeeze(-1)\n",
    "        a_j = a_j.squeeze(-1)\n",
    "        pool = nn.MaxPool2d(40)\n",
    "        a_r_p = pool(a_r)\n",
    "        a_j_p= pool(a_j)\n",
    "        a_p = torch.stack([a_r_p, a_j_p], dim = -1)\n",
    "        \n",
    "        return a_p\n",
    "        \n",
    "    def torch_conj(self, a_tensor):\n",
    "\n",
    "        # 复共轭\n",
    "        otf_conj = torch.cat([a_tensor.index_select(-1, torch.tensor([0])), a_tensor.index_select(-1, torch.tensor([1])) * -1],dim = -1)\n",
    "        return otf_conj\n",
    "\n",
    "    def shift2d(self,a_tensor):\n",
    "\n",
    "        x_shift = (np.shape(a_tensor)[0]+1)//2\n",
    "        y_shift = (np.shape(a_tensor)[1]+1)//2\n",
    "        shift2d = torch.roll(a_tensor,shifts = (x_shift, y_shift), dims = (0,1))\n",
    "        return shift2d\n",
    "\n",
    "    def ishift2d(self, a_tensor):\n",
    "\n",
    "        x_shift = (np.shape(a_tensor)[0]+1)//2\n",
    "        y_shift = (np.shape(a_tensor)[1]+1)//2\n",
    "        ishift2d = torch.roll(a_tensor,shifts = (-x_shift, -y_shift), dims = (0,1))\n",
    "        return ishift2d\n",
    "\n",
    "    def psf2otf(self, psf, psf_size):\n",
    "\n",
    "        # psf = F.pad()\n",
    "        psf = self.ishift2d(psf)\n",
    "        otf = torch.fft(psf, signal_ndim = 2)\n",
    "        return otf\n",
    "\n",
    "    def fftconv2d(self, img, psf_pad, otf=None, adjoint=False, phase=True):\n",
    "        # real2complex\n",
    "        # if len(img.shape) == 4:\n",
    "        if img.shape[-1] != 2:\n",
    "            img_j = torch.zeros_like(img)\n",
    "            img = torch.stack([img, img_j], dim=-1)\n",
    "\n",
    "        pad_one, pad_two = int(np.ceil((self.tile_size * self.tiling_factor  - img.shape[-2])/2)), int(np.floor((self.tile_size * self.tiling_factor - img.shape[-3])//2))\n",
    "        img_pad = F.pad(img,(0, 0, pad_one, pad_two, pad_one, pad_two), \"constant\", 0)          \n",
    "        \n",
    "        img_pad_fft2d = torch.fft(img_pad, signal_ndim = 2)\n",
    "        \n",
    "        otf = self.psf2otf(psf_pad, psf_size = self.tile_size * self.tiling_factor)\n",
    "        otf = otf.unsqueeze(0)\n",
    "        \n",
    "        if adjoint:\n",
    "            result = torch.ifft(img_pad_fft2d * self.torch_conj(otf), signal_ndim = 2)\n",
    "        else:\n",
    "            result = torch.ifft(img_pad_fft2d * otf, signal_ndim = 2)\n",
    "\n",
    "        if phase:  \n",
    "            result = result\n",
    "        else:\n",
    "            result = index_select(-1, torch.tensor([0]))\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (28) must match the size of tensor b (160) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-efbb6504c612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# forward + backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3a8ba90b40c1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsf_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0motf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# nn.MaxPool2d(40, 40)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3a8ba90b40c1>\u001b[0m in \u001b[0;36mfftconv2d\u001b[0;34m(self, img_pad, psf_pad, otf, adjoint, phase)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_pad_fft2d\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_conj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0motf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_pad_fft2d\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0motf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (28) must match the size of tensor b (160) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "        sum_loss = 0.0\n",
    "        # 数据读取\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    " \n",
    "            # forward + backward\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    " \n",
    "            # 每训练100个batch打印一次平均loss\n",
    "            sum_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %d] loss: %.03f'\n",
    "                      % (epoch + 1, i + 1, sum_loss / 100))\n",
    "                sum_loss = 0.0\n",
    "        # 每跑完一次epoch测试一下准确率\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                # 取得分最高的那个类\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            print('第%d个epoch的识别准确率为：%d%%' % (epoch + 1, (100 * correct / total)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = fft_conv2d()\n",
    "input = torch.randn((12,1,160,160),requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'img_pad' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c725ecce409e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-933b905420ec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsf_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0motf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-933b905420ec>\u001b[0m in \u001b[0;36mfftconv2d\u001b[0;34m(self, img, psf_pad, otf, adjoint, phase)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mpad_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_two\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtiling_factor\u001b[0m  \u001b[0;34m-\u001b[0m \u001b[0mimg_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtiling_factor\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mimg_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mimg_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_two\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_two\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'img_pad' referenced before assignment"
     ]
    }
   ],
   "source": [
    "output = layer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([12, 32])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(output)\n",
    "\n",
    "# img_pad_fft2d = torch.fft(ima_com, signal_ndim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([12, 3, 20, 20, 2])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "otf_conj = torch.cat([a_tensor.index_select(-1, torch.tensor([0])), a_tensor.index_select(-1, torch.tensor([1])) * -1],dim = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_lists = layer.psf_pad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.randn(32,32,2)\n",
    "a_r, a_j = a.split(1,-1)\n",
    "# b = torch.transpose(a, -2,-1)\n",
    "# c = torch.transpose(b, -2,-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_r= a_r.squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 32])"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(a_r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, parameter in layer.named_parameters():\n",
    "    print(name,':',parameter)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 40\n",
    "kernel_size = 32\n",
    "tiling_factor = 4\n",
    "pad_one, pad_two = int(np.ceil((tile_size - kernel_size)/2)), int(np.floor((tile_size - kernel_size)//2))\n",
    "kernels_lists = [[nn.Parameter(torch.rand(kernel_size, kernel_size, 2)) for i in range(tiling_factor)]for j in range(tiling_factor)]\n",
    "kernels_pad=[[F.pad(kernel, (0,0,pad_one,pad_two, pad_one,pad_two), 'constant', 0) for kernel in kernels]for kernels in kernels_lists]\n",
    "\n",
    "psf = torch.cat([torch.cat(kernel_list, dim=0) for kernel_list in kernels_pad], dim=1)\n",
    "\n",
    "psf_s = torch.fft(psf, signal_ndim = 2)\n",
    "\n",
    "x_shift = (np.shape(psf_s)[0]+1)//2\n",
    "y_shift = (np.shape(psf_s)[1]+1)//2\n",
    "\n",
    "psf_s_shift = torch.roll(psf_s, shifts = (x_shift, y_shift), dims = (0,1))\n",
    "\n",
    "# complex2real\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose (0, 1) dimentions as H and W\n",
    "tile_size = 40\n",
    "kernel_size = 32\n",
    "tiling_factor = 4\n",
    "\n",
    "def torch_conj(a_tensor):\n",
    "\n",
    "    # 复共轭\n",
    "    otf_conj = torch.cat([a_tensor.index_select(-1, torch.tensor([0])), a_tensor.index_select(-1, torch.tensor([1])) * -1],dim = -1)\n",
    "    return otf_conj\n",
    "\n",
    "def shift2d(a_tensor):\n",
    "\n",
    "    x_shift = (np.shape(a_tensor)[0]+1)//2\n",
    "    y_shift = (np.shape(a_tensor)[1]+1)//2\n",
    "    shift2d = torch.roll(a_tensor,shifts = (x_shift, y_shift), dims = (0,1))\n",
    "    return shift2d\n",
    "\n",
    "def ishift2d(a_tensor):\n",
    "\n",
    "    x_shift = (np.shape(a_tensor)[0]+1)//2\n",
    "    y_shift = (np.shape(a_tensor)[1]+1)//2\n",
    "    ishift2d = torch.roll(a_tensor,shifts = (-x_shift, -y_shift), dims = (0,1))\n",
    "    return ishift2d\n",
    "\n",
    "def ptf2otf(psf, psf_size):\n",
    "\n",
    "    # psf = F.pad()\n",
    "    psf = ishift2d(psf)\n",
    "    otf = torch.fft(tmp, signal_ndim = 2)\n",
    "    return otf\n",
    "\n",
    "def fft_conv2d(img_pad, psf_pad, otf=None, adjoint=False, phase=True):\n",
    "    # real2complex\n",
    "    img_pad_fft2d = torch.rfft(img_pad, signal_ndim = 2)\n",
    "    \n",
    "    otf = ptf2otf(psf_pad, psf_size = tile_size * tiling_factor)\n",
    "    \n",
    "    if adjoint:\n",
    "        result = torch.ifft(img_fft * torch_conj(otf), signal_ndim = 2)\n",
    "    else:\n",
    "        result = torch.ifft(img_fft * otf, signal_ndim = 2)\n",
    "\n",
    "    if phase:  \n",
    "        result = result\n",
    "    else:\n",
    "        result = index_select(-1, torch.tensor([0]))\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.tensor([0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.rand(5,5,2)\n",
    "d = c.index_select(-1, torch.tensor([1])) * -1\n",
    "e = torch.cat([c.index_select(-1, torch.tensor([0])), c.index_select(-1, torch.tensor([1])) * -1],dim = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Parameter(torch.rand(5,5))\n",
    "\n",
    "a_fft = torch.rfft(a, signal_ndim = 2)\n",
    "\n",
    "a_shift = shift2d(a_fft)\n",
    "a_ishift = ishift2d(a_shift)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test fft and shift\n",
    "a = nn.Parameter(torch.rand(5,5,2))\n",
    "print(a)\n",
    "a_s = torch.fft(a, signal_ndim = 2)\n",
    "print(a_s)\n",
    "x_shift = (np.shape(a_s)[0]+1)//2\n",
    "y_shift = (np.shape(a_s)[1]+1)//2\n",
    "a_shift = torch.roll(a_s, shifts = (x_shift, y_shift), dims = (0,1))\n",
    "print(a_s)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image Fourier transform\n",
    "Ima = Image.open('3.bmp')\n",
    "Ima = Ima.convert('L')\n",
    "Ima_g = np.array(Ima)\n",
    "print(np.shape(Ima_g))\n",
    "Ima_g = torch.from_numpy(Ima_g)\n",
    "Ima_g = Ima_g.float()\n",
    "print(np.shape(Ima_g))\n",
    "Ima_r = torch.FloatTensor(Ima_g)\n",
    "Ima_j = torch.zeros(256,256)\n",
    "Ima_com = torch.cat([Ima_r.unsqueeze(-1), Ima_j.unsqueeze(-1)], dim=2)\n",
    "Ima_s = torch.fft(Ima_com, signal_ndim = 2)\n",
    "print(np.shape(Ima_s))\n",
    "x_shift = (np.shape(Ima_s)[0]+1)//2\n",
    "y_shift = (np.shape(Ima_s)[1]+1)//2\n",
    "Ima_shift = torch.roll(Ima_s, shifts = (x_shift, y_shift), dims = (0,1))\n",
    "print(np.shape(Ima_shift))\n",
    "Ima_shift_np = np.array(Ima_shift)\n",
    "Ima_shift_np = np.sqrt(np.square(Ima_shift_np[:,:,0])+np.square(Ima_shift_np[:,:,1]))\n",
    "# Ima_png = np.abs(Ima_shift)\n",
    "# Ima_png = Ima_png.numpy()\n",
    "img = Image.fromarray(Ima_shift_np)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = [[0, 0, 0 ,0],[0, 0, 0 ,0],[0, 0, 0 ,0],[0, 0 ,0 ,0]]\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        kernel[i][j] = nn.Parameter(torch.rand(40, 40, 2))       "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fft_conv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, tile_size, kernel_size, tiling_factor):\n",
    "        names = self.__dict__\n",
    "        super(fft_conv2d, self).__init__()\n",
    "        self.names = names\n",
    "        self.tile_size = tile_size\n",
    "        self.kernel_size = kernel_size\n",
    "        self.tiling_factor = tiling_factor\n",
    "        # self.w = nn.Parameter(torch.rand(self.kernel_size, self.kernel_size, 2))\n",
    "        pad_one, pad_two = int(np.ceil((self.tile_size - self.kernel_size)/2)), int(np.floor((self.tile_size - self.kernel_size)//2))\n",
    "\n",
    "        self.kernels_lists = [[0, 0, 0 ,0],[0, 0, 0 ,0],[0, 0, 0 ,0],[0, 0 ,0 ,0]]\n",
    "        \n",
    "        for i in range(self.tiling_factor):\n",
    "            for j in range(self.tiling_factor):\n",
    "                # self.names['kernels_' + str(i) + str(j)] = nn.Parameter(torch.rand(self.kernel_size, self.kernel_size, 2))\n",
    "                exec('self.kernel_{}{} = nn.Parameter(torch.rand(self.kernel_size, self.kernel_size, 2))'.format(i,j))\n",
    "                exec('self.kernels_lists[i][j] = self.kernel_{}{}'.format(i,j))\n",
    "        kernels_pad =[[F.pad(kernel, (0,0,pad_one,pad_two, pad_one,pad_two), 'constant', 0) for kernel in kernels]for kernels in                                    self.kernels_lists]\n",
    "        self.psf_pad = torch.cat([torch.cat(kernel_list, dim=0) for kernel_list in kernels_pad], dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "fff = fft_conv2d(40 ,32 ,4)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = fff.psf_pad"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, parameter in fff.named_parameters():\n",
    "    print(name,':',parameter)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "\n",
    "    for j in range(2):\n",
    "        b = torch.randn(5,5)\n",
    "        if j > 0:\n",
    "            b = torch.cat([b, b], dim = )\n",
    "             \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(5,5)\n",
    "c= b.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "np.shape(b)\n",
    "np.shape(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([c,b],dim =-1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Linear"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mm()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    pass"
   ]
  }
 ]
}